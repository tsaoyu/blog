---
layout: post
title:  "Alignment of Large Models"
date:   2024-07-13 11:27:00
categories: [Robotics & AI]
---

Over the past few years, I have worked on various AI projects and have semi-settled in the area of aligning large language models as my career. My daily job involves numerous experiments with generative language models to understand their shortcomings and develop plans to remedy their imperfections.

My journey began in the summer of 2015 at the NGCM (Next Generation Computational Modelling) summer school in Southampton, nearly ten years ago. There, we were introduced to the basics of IPython notebooks, good conventions in version control and testing, Pandas, and CUDA. My technology stack hasn't changed much since joining Huawei and Alibaba, which suggests that everyone at that summer school had a good understanding of the transformative impact computation would have on the industry.

During my PhD, I didn't focus much on the 'publish or perish' game and had virtually no serious publications in core research tracks. Instead, I spent much of my time working with robots and daydreaming about applying useful AI to them. It is now clear that working on maritime robots assumed a significant computational budget and sensor availability. The level of intelligence was limited by our computational resources (a single Raspberry Pi), the team's budget, and the progress of general pretrained models.

Two conflicting streams of thought occupied my mind until the emergence of ChatGPT: a) developing quick, effective, but not overly smart solutions for intermediate problems, and b) building an ideal environment for smart ideas that might not work in the short term. The former was more about student robotics teams and competitions, while the latter pertained to my research-oriented PhD thesis in a simulated environment. In retrospect, my PhD thesis was lacking in execution and innovation. It discussed finding suitable configurations in a large design space (solved by a genetic algorithm) and learning policies from data to handle uncertainty (solved by PPO, a reinforcement learning algorithm). There was a significant gap between my work with a small sailing robot and my proposed solution for long-term self-sustained robotic power management.

It took me several years to explore ideas around this, and the solution clearly revolved around robots and AI. The first attempt came from the robot control problem: how much can we push the limits of robots in the most challenging environments? I might find some insights while building RL-based controllers. The second attempt involved identifying needs wherever AI could make a significant contribution.

So this post is my long-term thought on what might work in 5 or even 10 years based on my best guess. 

## Robotics to intelligence


## Chatbot to intelligence


## Converge or diverge


## What we do it for?


## Rational through alignment 


## Scalable oversight 


## Give away control 


